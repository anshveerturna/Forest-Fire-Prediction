# -*- coding: utf-8 -*-
"""3_model_with_cam.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wvCV09BX2upuozb1xmXj0GoeCVwCFMcw

<h1 align=center >Wildfire Prediction in Satellite Imagery</h1>

<br>

<img  src="https://raw.githubusercontent.com/doguilmak/Wildfire-Prediction-from-Satellite-Imagery/main/assets/wildfire_canada.png" width=1000  height=250 alt="github.com/doguilmak/Wildfire-Prediction-from-Satellite-Imagery"/>

<small>Picture Source: <a href="https://github.com/doguilmak/Wildfire-Prediction-from-Satellite-Imagery">Doğu İlmak GitHub</a></small>


<br>

<h2>Objectives</h2>

<p>Using <i>longitude</i> and <i>latitude</i> coordinates for each wildfire spot <i>(> 0.01 acres burned)</i> found on the dataset above we extracted satellite images of those areas using <b>MapBox API</b> to create a more convenient format of the dataset for <i>deep learning</i> and building a model that can predict whether an area is at <b>risk of a wildfire</b> or <b>not</b>.</p>

<br>

<h2>About Dataset</h2>

<p>This dataset contains satellite images <i>(350x350px)</i> in 2 classes:</p>

<ul>
  <li>Wildfire : 22710 images</li>
  <li>No wildfire : 20140 images</li>
</ul>

<p>The data was divided into train, test and validation with these percentages:</p>

<ul>
  <li>Train : ~70%</li>
  <li>Test : ~15%</li>
  <li>Validation : ~15%</li>
</ul>

<p>To download the dataset from Kaggle, you need to have a kaggle account.</p>
<ul>
 <li>Dataset download link: <a href='https://www.kaggle.com/datasets/abdelghaniaaba/wildfire-prediction-dataset/download?datasetVersionNumber=1'>Dataset</a></li>
 <li>Dataset on Kaggle: <a href='https://www.kaggle.com/datasets/abdelghaniaaba/wildfire-prediction-dataset'>Wildfire Prediction Dataset (Satellite Images)</a></li>
</ul>

<br>

<h2>Sources</h2>
<ul>
  <li><a href='https://open.canada.ca/data/en/dataset/9d8f219c-4df0-4481-926f-8a2a532ca003'>Refer to Canada's Website for the Original Wildfires Data (Forest Fires - Open Government Portal)</a>
  <li><a href='https://www.donneesquebec.ca/fr/licence/'>Original License For the Data (Creative Commons 4.0 Attribution (CC-BY) license – Quebec)</a></li>
</ul>

<br>

<h2>Table of Contents</h2>

<div class="alert alert-block alert-info" style="margin-top: 20px">
  <ul>
      <li><a href="https://#unzip_data"> Unzip data</a></li>
      <li><a href="https://#auxiliary"> Imports and Auxiliary Function </a></li>
      <li><a href="https://#examine_files">Examine Files</a></li>
      <li><a href="https://#Display">Display and Analyze Image With No Trees</a></li>
  </ul>

  <br>

  <p>Estimated Time Needed: <strong>25 min</strong></p>

</div>

<br>

<h2 align=center id="unzip_data">Upload Data</h2>
"""

from google.colab import drive
drive.mount('/content/gdrive/')

"""<br>

<h2 align=center id="auxiliary">Imports and Auxiliary Function</h2>

<p>The following are the libraries we are going to use for this lab:</p>
"""

import os
import tensorflow as tf
import datetime
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import scipy as sp
import cv2
import numpy as np

for device in tf.config.list_physical_devices():
    print(f"{device.name}")

try:
    # %tensorflow_version only exists in Colab.
    get_ipython().run_line_magic('tensorflow_version', '2.x')
except Exception:
    pass

from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential, Model, load_model
from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, BatchNormalization,  GlobalAveragePooling2D
from tensorflow.keras.callbacks import TensorBoard

import warnings
warnings.filterwarnings("ignore")

from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True

def plot_loss(history):
  plt.figure(figsize=(20, 10))
  sns.set_style('whitegrid')
  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  plt.title('Wildfire Model Loss')
  plt.ylabel('Loss')
  plt.xlabel('Epochs')
  plt.legend(['loss', 'val_loss'], loc='upper left')
  plt.show()

def plot_acc(history):
  plt.figure(figsize=(20, 10))
  sns.set_style('whitegrid')
  plt.plot(history.history['accuracy'])
  plt.plot(history.history['val_accuracy'])
  plt.title('Wildfire Model Accuracy')
  plt.ylabel('Accuracy')
  plt.xlabel('Epoch')
  plt.legend(['accuracy', 'val_accuracy'], loc='upper left')
  plt.show()

def compute_class_freqs(labels):
    
  # total number of patients (rows)
  N = np.shape(labels)[0]
  
  positive_frequencies = np.sum(labels, axis = 0) / N
  negative_frequencies = 1 - positive_frequencies

  return positive_frequencies, negative_frequencies

"""<br>

<h2 align=center id="examine_files">Dataset Preparation</h2>
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/MyDrive/Colab Notebooks/AI Data/

"""<p><i><b>Please uncomment following block if you are running for the first time.</b></i></p>"""

#!mkdir -p saved_model
#!mkdir -p predictions
#!mkdir -p model_plots

# Commented out IPython magic to ensure Python compatibility.
# %ls

train_path = "/content/gdrive/MyDrive/Colab Notebooks/AI Data/train"
valid_path = "/content/gdrive/MyDrive/Colab Notebooks/AI Data/valid"
test_path = "/content/gdrive/MyDrive/Colab Notebooks/AI Data/test"

im_size = 224 #@param {type:"slider", min:64, max:350, step:1}
image_resize = (im_size, im_size, 3) 
batch_size_training = 100 #@param {type:"number"}
batch_size_validation = 100 #@param {type:"number"}
batch_size_test = 100 #@param {type:"number"}
num_classes = 2 #@param {type:"number"}

data_generator = ImageDataGenerator(dtype='float32', rescale= 1./255.)

train_generator = data_generator.flow_from_directory(train_path,
                                                   batch_size = batch_size_training,
                                                   target_size = (im_size, im_size),
                                                   class_mode = 'categorical')

valid_generator = data_generator.flow_from_directory(valid_path,
                                                   batch_size = batch_size_validation,
                                                   target_size = (im_size, im_size),
                                                   class_mode = 'categorical')

class_mapping = train_generator.class_indices
class_mapping

first_batch_train = train_generator.next()
first_batch_train

first_batch_valid = valid_generator.next()
first_batch_valid

labels = np.array(['nowildfire', 'wildfire'])

freq_pos, freq_neg = compute_class_freqs(train_generator.labels)

data = pd.DataFrame({"Class": labels, "Label": "Positive", "Value": freq_pos})
for i in range(2):
  data = data.append([{"Class": labels[i], "Label": "Negative", "Value": freq_neg}])
plt.figure(figsize=(20, 7))
plt.title("Frequency of Each Class")
f = sns.barplot(x="Class", y="Value", hue="Label" ,data=data)

"""<br>

<h2 align=center id="fit_custom_model">Compile and Fit Custom Model</h2>

<p>If you can use my model, please uncomment the following code block and go to <code>model.summary()</code> block.</p>
"""

model = load_model('saved_model/custom_best_model.h5')

def base_model(input_shape, repetitions): 
  
  input_ = tf.keras.layers.Input(shape=input_shape, name='input')
  x = input_
  
  for i in range(repetitions):
    n_filters = 2**(4 + i)
    x = Conv2D(n_filters, 3, activation='relu')(x)
    x = BatchNormalization()(x)
    x = MaxPool2D(2)(x)

  return x, input_

def final_model(input_shape, repetitions):
    
    x, input_ = base_model(input_shape, repetitions)

    x = Conv2D(64, 3, activation='relu')(x)
    x = GlobalAveragePooling2D()(x)
    class_out = Dense(num_classes, activation='softmax', name='class_out')(x)

    model = Model(inputs=input_, outputs=class_out)

    print(model.summary())
    return model

model = final_model(image_resize, 4)

from tensorflow.keras.utils import plot_model
plot_model(model, show_shapes=True, show_layer_names=True, to_file='model_plots/custom_model.png')

get_ipython().system('rm -rf logs')

model.compile(
    optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"]
)

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir)
checkpoint = tf.keras.callbacks.ModelCheckpoint('saved_model/custom_best_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')

callbacks_list = [checkpoint, tensorboard_callback]

num_epochs = 2 #@param {type:"number"}
steps_per_epoch_training = len(train_generator)
steps_per_epoch_validation = len(valid_generator)

history = model.fit_generator(
    train_generator,
    steps_per_epoch=steps_per_epoch_training,
    epochs=num_epochs,
    validation_data=valid_generator,
    validation_steps=steps_per_epoch_validation,
    verbose=1,
    callbacks=[callbacks_list],
)

"""<br>

<h2 align=center id="analize_model">Analize the Model</h2>
"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

"""<p>Please modify the path of <code>logs</code>.</p>"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir /content/gdrive/MyDrive/logs

plot_acc(history)

plot_loss(history)

model.save('saved_model/custom_model')
print("Model saved!")

# model.save('saved_model/custom_model.h5')
# print("Model saved!")

"""<h2 align=center id="make_dataframe">Make DataFrame for the Predictions</h2>"""

test_generator = data_generator.flow_from_directory(test_path,
                                                   batch_size = batch_size_test,
                                                   target_size = (im_size, im_size),
                                                   class_mode = 'categorical')

filenames = test_generator.filenames

pred = model.predict_generator(test_generator, steps=len(test_generator), verbose=1).round(3)

filenames_df = pd.DataFrame(filenames, columns=['File Path'])
pred_df = pd.DataFrame(pred, columns=['No Wildfire Probability', 'Wildfire Probability'])
model_predictions = pd.concat([filenames_df, pred_df], axis=1)
model_predictions

file_name='/content/gdrive/MyDrive/Colab Notebooks/AI Data/predictions/custom_model_predictions.csv'
model_predictions.to_csv(file_name, sep=',', encoding='utf-8')

"""<br>
<h2 align=center id="build_cam">Building Class Activation Maps</h2>
"""

outputs = [layer.output for layer in model.layers[1:9]]

vis_model = Model(model.input, outputs)

layer_names = []
for layer in outputs:
    layer_names.append(layer.name.split("/")[0])

print("Layers that will be used for visualization: ")
print(layer_names)

gap_weights = model.layers[-1].get_weights()[0]
gap_weights.shape

cam_model  = Model(inputs=model.input, outputs=(model.layers[-3].output,model.layers[-1].output))
cam_model.summary()

plot_model(cam_model, show_shapes=True, show_layer_names=True, to_file='model_plots/cam_model.png')

cam_model.save('saved_model/cam_model')
print("Model saved!")

# cam_model.save('saved_model/cam_model.h5')
# print("Model saved!")

def show_cam(image_value, features, results):

  features_for_img = features[0]
  prediction = results[0]

  class_activation_weights = gap_weights[:,0]
  class_activation_features = sp.ndimage.zoom(features_for_img, (im_size/10, im_size/10, 1), order=2)  
  cam_output  = np.dot(class_activation_features,class_activation_weights)
  
  # Visualize the results
  plt.figure(figsize=(12, 12))
  plt.imshow(cam_output, cmap='jet', alpha=0.5)
  plt.imshow(tf.squeeze(image_value), alpha=0.5)
  plt.title('Class Activation Map')
  plt.figtext(.5, .05, f"No Wildfire Probability: {results[0][0] * 100}%\nWildfire Probability: {results[0][1] * 100}%", ha="center", fontsize=12, bbox={"facecolor":"green", "alpha":0.5, "pad":3})
  plt.colorbar()
  plt.show()

def convert_and_classify(image):

  img = cv2.imread(image)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

  img = cv2.resize(img, (im_size, im_size)) / 255.0
  tensor_image = np.expand_dims(img, axis=0)
  features, results = cam_model.predict(tensor_image)
  
  # generate the CAM
  show_cam(tensor_image, features, results)

convert_and_classify('/content/gdrive/MyDrive/Colab Notebooks/AI Data/test/nowildfire/-113.91777,50.901087.jpg')

convert_and_classify('/content/gdrive/MyDrive/Colab Notebooks/AI Data/test/wildfire/-59.03238,51.85132.jpg')

"""<br>
<h2 align=center id="upload_predict">Upload and Predict Your Picture!</h2>
"""

from google.colab import files
from keras.preprocessing import image
from numpy import asarray

uploaded = files.upload()

for fn in uploaded.keys():
 
  # CAM Model Prediction
  width = im_size
  height = im_size
  dim = (width, height)
  path = '/content/gdrive/MyDrive/Colab Notebooks/AI Data/' + fn
  img = cv2.imread(path)
  print('CAM Model Predicton:\n')
  convert_and_classify(path)
  
  # Custom Model Prediction
  # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  # img = cv2.resize(img, dim)
  # x = asarray(img)
  # x = np.expand_dims(x, axis=0)
  # image_tensor = np.vstack([x])
  # classes = model.predict(image_tensor)
  # print('Custom Model Predicton:\n')
  # print("No Wildfire Probability: %", round(classes[0][0] * 100, 2))
  # print("Wildfire Probability: %", round(classes[0][1] * 100, 2))

"""<br>

<h2>Contact Me</h2>
<p>If you have something to say to me please contact me:</p>

<ul>
  <li>Twitter: <a href="https://twitter.com/Doguilmak">Doguilmak</a></li>
  <li>Mail address: doguilmak@gmail.com</li>
</ul>
"""

from datetime import datetime
print(f"Changes have been made to the project on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")