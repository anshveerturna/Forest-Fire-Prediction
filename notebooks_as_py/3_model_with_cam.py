# -*- coding: utf-8 -*-
"""3_model_with_cam.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DMRrdUtsMLWNDMBFGBqnoFWBm4f6qsTD

<h1 align=center >Wildfire Prediction in Satellite Imagery</h1>

<br>

<img  src="https://raw.githubusercontent.com/doguilmak/Wildfire-Prediction-from-Satellite-Imagery/main/assets/wildfire_canada.png" width=1000  height=250 alt="github.com/doguilmak/Wildfire-Prediction-from-Satellite-Imagery"/>

<small>Picture Source: <a href="https://github.com/doguilmak/Wildfire-Prediction-from-Satellite-Imagery">Doğu İlmak GitHub</a></small>

<br>

<h2>Predicting Wildfires with Convolutional Neural Networks (CNNs)</h2>

<p>Wildfires pose a significant threat to ecosystems, wildlife, and human lives, making early detection and prediction crucial for effective wildfire management. Convolutional Neural Networks (CNNs) have emerged as a powerful tool for predicting wildfires due to their ability to extract complex patterns from spatial data, such as satellite images and weather data. CNNs can analyze various factors that contribute to wildfire risk, including vegetation density, temperature, humidity, and wind speed. By training CNNs on historical wildfire data and environmental factors, these models can learn to identify patterns indicative of potential wildfire outbreaks. One of the key advantages of using CNNs for wildfire prediction is their ability to process large-scale, high-resolution satellite imagery quickly. This allows for real-time monitoring of wildfire-prone areas, enabling early detection and timely deployment of firefighting resources.</p>

<br>

<p>Additionally, CNNs can improve the accuracy of wildfire prediction models by integrating data from multiple sources, such as satellite imagery, weather stations, and historical fire records. This holistic approach provides a comprehensive view of wildfire risk factors, leading to more reliable predictions.</p>

<br>

<h2>Wildfire Prediction Dataset</h2>

<p>This dataset consists of satellite images with a resolution of 350x350 pixels, categorized into two classes: Wildfire and No Wildfire. The dataset contains a total of 42,850 images, with 22,710 images belonging to the Wildfire class and 20,140 images belonging to the No Wildfire class. To facilitate model training and evaluation, the dataset has been divided into three subsets: training, testing, and validation. The distribution of images among these subsets is as follows:</p>

<ul>
    <li><b>Training Set:</b> Approximately 70% of the dataset, used for training the model.</li>
  <li><b>Testing Set:</b> Approximately 15% of the dataset, used for evaluating the model's performance.</li>
  <li><b>Validation Set:</b> Approximately 15% of the dataset, used for fine-tuning hyperparameters and validating the model's performance.</li>
</ul>

<p>Each image in the dataset represents a snapshot of the Earth's surface, captured by satellite imagery. These images contain valuable information about vegetation, land cover, and other environmental factors that can be used to predict the likelihood of wildfires.</p>

<br>

<h2>Objectives</h2>

<p>Using <i>longitude</i> and <i>latitude</i> coordinates for each wildfire spot <i>(> 0.01 acres burned)</i> found on the dataset above we extracted satellite images of those areas using <b>MapBox API</b> to create a more convenient format of the dataset for <i>deep learning</i> and building a model that can predict whether an area is at <b>risk of a wildfire</b> or <b>not</b>.</p>

<br>

<p>To download the dataset from Kaggle, you need to have a kaggle account.</p>
<ul>
 <li>Dataset download link: <a href='https://www.kaggle.com/datasets/abdelghaniaaba/wildfire-prediction-dataset/download?datasetVersionNumber=1'>Dataset</a></li>
 <li>Dataset on Kaggle: <a href='https://www.kaggle.com/datasets/abdelghaniaaba/wildfire-prediction-dataset'>Wildfire Prediction Dataset (Satellite Images)</a></li>
</ul>

<br>

<h2>Sources</h2>
<ul>
  <li><a href='https://open.canada.ca/data/en/dataset/9d8f219c-4df0-4481-926f-8a2a532ca003'>Refer to Canada's Website for the Original Wildfires Data (Forest Fires - Open Government Portal)</a>
  <li><a href='https://www.donneesquebec.ca/fr/licence/'>Original License For the Data (Creative Commons 4.0 Attribution (CC-BY) license – Quebec)</a></li>
</ul>

<br>

<h2>Table of Contents</h2>

<div class="alert alert-block alert-info" style="margin-top: 20px">
  <ul>
      <li><a href="https://#unzip_data"> Unzip data</a></li>
      <li><a href="https://#auxiliary"> Imports and Auxiliary Function </a></li>
      <li><a href="https://#examine_files">Examine Files</a></li>
      <li><a href="https://#Display">Display and Analyze Image With No Trees</a></li>
  </ul>

  <br>

  <p>Estimated Time Needed: <strong>25 min</strong></p>

</div>

<br>

<h2 align=center id="unzip_data">Upload Data</h2>
"""

from google.colab import drive
drive.mount('/content/gdrive/')

"""<br>

<h2 align=center id="auxiliary">Imports and Auxiliary Function</h2>

<p>The following are the libraries we are going to use for this lab:</p>
"""

import os
import tensorflow as tf
import datetime
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import scipy as sp
import cv2
import numpy as np

for device in tf.config.list_physical_devices():
    print(f"{device.name}")

try:
    # %tensorflow_version only exists in Colab.
    get_ipython().run_line_magic('tensorflow_version', '2.x')
except Exception:
    pass

from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential, Model, load_model
from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, BatchNormalization,  GlobalAveragePooling2D
from tensorflow.keras.callbacks import TensorBoard

import warnings
warnings.filterwarnings("ignore")

from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True

def plot_loss(history):
  plt.figure(figsize=(20, 10))
  sns.set_style('whitegrid')
  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  plt.title('Wildfire Model Loss')
  plt.ylabel('Loss')
  plt.xlabel('Epochs')
  plt.legend(['loss', 'val_loss'], loc='upper left')
  plt.show()

def plot_acc(history):
  plt.figure(figsize=(20, 10))
  sns.set_style('whitegrid')
  plt.plot(history.history['accuracy'])
  plt.plot(history.history['val_accuracy'])
  plt.title('Wildfire Model Accuracy')
  plt.ylabel('Accuracy')
  plt.xlabel('Epoch')
  plt.legend(['accuracy', 'val_accuracy'], loc='upper left')
  plt.show()

"""<br>

<h2 align=center id="examine_files">Dataset Preparation</h2>
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/MyDrive/Colab Notebooks/AI Data/

"""<p><i><b>Please uncomment following block if you are running for the first time.</b></i></p>"""

#!mkdir -p saved_model
#!mkdir -p predictions
#!mkdir -p model_plots

# Commented out IPython magic to ensure Python compatibility.
# %ls

train_path = "/content/gdrive/MyDrive/Colab Notebooks/AI Data/train"
valid_path = "/content/gdrive/MyDrive/Colab Notebooks/AI Data/valid"
test_path = "/content/gdrive/MyDrive/Colab Notebooks/AI Data/test"

im_size = 224 #@param {type:"slider", min:64, max:350, step:1}
image_resize = (im_size, im_size, 3)
batch_size_training = 100 #@param {type:"number"}
batch_size_validation = 100 #@param {type:"number"}
batch_size_test = 100 #@param {type:"number"}
num_classes = 2 #@param {type:"number"}

data_generator = ImageDataGenerator(dtype='float32', rescale= 1./255.)

train_generator = data_generator.flow_from_directory(train_path,
                                                   batch_size = batch_size_training,
                                                   target_size = (im_size, im_size),
                                                   class_mode = 'categorical')

valid_generator = data_generator.flow_from_directory(valid_path,
                                                   batch_size = batch_size_validation,
                                                   target_size = (im_size, im_size),
                                                   class_mode = 'categorical')

class_mapping = train_generator.class_indices
class_mapping

first_batch_train = train_generator.next()
first_batch_train

first_batch_valid = valid_generator.next()
first_batch_valid

# labels = np.array(['nowildfire', 'wildfire'])
class_names = list(train_generator.class_indices.keys())
print("Class names :", class_names_valid)

custom_palette = {'nowildfire': 'skyblue', 'wildfire': 'orange'}

data = pd.DataFrame({'Class': class_names, 'Count': [sum(train_generator.labels == c) for c in range(num_classes)]})

plt.figure(figsize=(20, 7))
sns.barplot(x='Class', y='Count', data=data, palette=custom_palette)
plt.title('Class Distribution in Training Set')
plt.xlabel('Class')
plt.ylabel('Count')
plt.show()

labels_train = train_generator.classes
unique_labels_train, label_counts_train = np.unique(labels_train, return_counts=True)

print("Number of unique labels in train data:", len(unique_labels_train))
for label, count in zip(unique_labels_train, label_counts_train):
    print("Label:", class_names[label], "- Count:", count)

custom_palette = {'nowildfire': 'skyblue', 'wildfire': 'orange'}

data = pd.DataFrame({'Class': class_names, 'Count': [sum(valid_generator.labels == c) for c in range(num_classes)]})

plt.figure(figsize=(20, 7))
sns.barplot(x='Class', y='Count', data=data, palette=custom_palette)
plt.title('Class Distribution in Validation Set')
plt.xlabel('Class')
plt.ylabel('Count')
plt.show()

labels_valid = valid_generator.classes
unique_labels_valid, label_counts_valid = np.unique(labels_valid, return_counts=True)

print("Number of unique labels in valid data:", len(unique_labels_valid))
for label, count in zip(unique_labels_valid, label_counts_valid):
    print("Label:", class_names_valid[label], "- Count:", count)

"""<br>

<h2 align=center id="fit_custom_model">Compile and Fit Custom Model</h2>

<p>If you can use my model, please uncomment the following code block and go to <code>model.summary()</code> block.</p>
"""

model = load_model('saved_model/custom_best_model.h5')

def base_model(input_shape, repetitions):

  input_ = tf.keras.layers.Input(shape=input_shape, name='input')
  x = input_

  for i in range(repetitions):
    n_filters = 2**(4 + i)
    x = Conv2D(n_filters, 3, activation='relu')(x)
    x = BatchNormalization()(x)
    x = MaxPool2D(2)(x)

  return x, input_

def final_model(input_shape, repetitions):

    x, input_ = base_model(input_shape, repetitions)

    x = Conv2D(64, 3, activation='relu')(x)
    x = GlobalAveragePooling2D()(x)
    class_out = Dense(num_classes, activation='softmax', name='class_out')(x)

    model = Model(inputs=input_, outputs=class_out)

    print(model.summary())
    return model

model = final_model(image_resize, 4)

from tensorflow.keras.utils import plot_model
plot_model(model, show_shapes=True, show_layer_names=True, to_file='model_plots/custom_model.png')

get_ipython().system('rm -rf logs')

model.compile(
    optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"]
)

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir)
checkpoint = tf.keras.callbacks.ModelCheckpoint('saved_model/custom_best_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')

callbacks_list = [checkpoint, tensorboard_callback]

num_epochs = 2 #@param {type:"number"}
steps_per_epoch_training = len(train_generator)
steps_per_epoch_validation = len(valid_generator)

history = model.fit_generator(
    train_generator,
    steps_per_epoch=steps_per_epoch_training,
    epochs=num_epochs,
    validation_data=valid_generator,
    validation_steps=steps_per_epoch_validation,
    verbose=1,
    callbacks=[callbacks_list],
)

"""<br>

<h2 align=center id="analize_model">Analize the Model</h2>
"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

"""<p>Please modify the path of <code>logs</code>.</p>"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir /content/gdrive/MyDrive/logs

plot_acc(history)

plot_loss(history)

model.save('saved_model/custom_model')
print("Model saved!")

# model.save('saved_model/custom_model.h5')
# print("Model saved!")

"""<h2 align=center id="make_dataframe">Make DataFrame for the Predictions</h2>"""

test_generator = data_generator.flow_from_directory(test_path,
                                                   batch_size = batch_size_test,
                                                   target_size = (im_size, im_size),
                                                   class_mode = 'categorical')

filenames = test_generator.filenames

pred = model.predict_generator(test_generator, steps=len(test_generator), verbose=1).round(3)

filenames_df = pd.DataFrame(filenames, columns=['File Path'])
pred_df = pd.DataFrame(pred, columns=['No Wildfire Probability', 'Wildfire Probability'])
model_predictions = pd.concat([filenames_df, pred_df], axis=1)
model_predictions

file_name='/content/gdrive/MyDrive/Colab Notebooks/AI Data/predictions/custom_model_predictions.csv'
model_predictions.to_csv(file_name, sep=',', encoding='utf-8')

"""<br>
<h2 align=center id="build_cam">Building Class Activation Maps</h2>
"""

outputs = [layer.output for layer in model.layers[1:9]]

vis_model = Model(model.input, outputs)

layer_names = []
for layer in outputs:
    layer_names.append(layer.name.split("/")[0])

print("Layers that will be used for visualization: ")
print(layer_names)

gap_weights = model.layers[-1].get_weights()[0]
gap_weights.shape

cam_model  = Model(inputs=model.input, outputs=(model.layers[-3].output,model.layers[-1].output))
cam_model.summary()

plot_model(cam_model, show_shapes=True, show_layer_names=True, to_file='model_plots/cam_model.png')

cam_model.save('saved_model/cam_model')
print("Model saved!")

# cam_model.save('saved_model/cam_model.h5')
# print("Model saved!")

def show_cam(image_value, features, results):

  features_for_img = features[0]
  prediction = results[0]

  class_activation_weights = gap_weights[:,0]
  class_activation_features = sp.ndimage.zoom(features_for_img, (im_size/10, im_size/10, 1), order=2)
  cam_output  = np.dot(class_activation_features,class_activation_weights)

  # Visualize the results
  plt.figure(figsize=(12, 12))
  plt.imshow(cam_output, cmap='jet', alpha=0.5)
  plt.imshow(tf.squeeze(image_value), alpha=0.5)
  plt.title('Class Activation Map')
  plt.figtext(.5, .05, f"No Wildfire Probability: {results[0][0] * 100}%\nWildfire Probability: {results[0][1] * 100}%", ha="center", fontsize=12, bbox={"facecolor":"green", "alpha":0.5, "pad":3})
  plt.colorbar()
  plt.show()

def convert_and_classify(image):

  img = cv2.imread(image)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

  img = cv2.resize(img, (im_size, im_size)) / 255.0
  tensor_image = np.expand_dims(img, axis=0)
  features, results = cam_model.predict(tensor_image)

  # generate the CAM
  show_cam(tensor_image, features, results)

convert_and_classify('/content/gdrive/MyDrive/Colab Notebooks/AI Data/test/nowildfire/-113.91777,50.901087.jpg')

convert_and_classify('/content/gdrive/MyDrive/Colab Notebooks/AI Data/test/wildfire/-59.03238,51.85132.jpg')

"""<br>
<h2 align=center id="upload_predict">Upload and Predict Your Picture!</h2>
"""

from google.colab import files
from keras.preprocessing import image
from numpy import asarray

uploaded = files.upload()

for fn in uploaded.keys():

  # CAM Model Prediction
  width = im_size
  height = im_size
  dim = (width, height)
  path = '/content/gdrive/MyDrive/Colab Notebooks/AI Data/' + fn
  img = cv2.imread(path)
  print('CAM Model Predicton:\n')
  convert_and_classify(path)

  # Custom Model Prediction
  # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  # img = cv2.resize(img, dim)
  # x = asarray(img)
  # x = np.expand_dims(x, axis=0)
  # image_tensor = np.vstack([x])
  # classes = model.predict(image_tensor)
  # print('Custom Model Predicton:\n')
  # print("No Wildfire Probability: %", round(classes[0][0] * 100, 2))
  # print("Wildfire Probability: %", round(classes[0][1] * 100, 2))

"""<br>

<h2>Contact Me</h2>
<p>If you have something to say to me please contact me:</p>

<ul>
  <li>Twitter: <a href="https://twitter.com/Doguilmak">Doguilmak</a></li>
  <li>Mail address: doguilmak@gmail.com</li>
</ul>
"""

from datetime import datetime
print(f"Changes have been made to the project on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")